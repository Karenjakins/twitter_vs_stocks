{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29d489e",
   "metadata": {},
   "source": [
    "# (1) Twitter Data\n",
    "## (1.1) Getting twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5765ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from path import Path\n",
    "\n",
    "from twarc import Twarc2, expansions\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f73f8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import bearer_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b804e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Twarc2(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42efd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'elonmusk'\n",
    "posts_dict = {\n",
    "    'date':[],\n",
    "    'text':[],\n",
    "    'like_count':[],\n",
    "    'quote_count':[],\n",
    "    'reply_count':[],\n",
    "    'retweet_count':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bde4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull posts from Twitter and create a dictionary\n",
    "user_timeline = client.timeline(user=user, exclude_replies=True, start_time=datetime.datetime(2017,1,20, 0, 0, 0) )\n",
    "for page in user_timeline:\n",
    "    result = expansions.flatten(page)\n",
    "    for tweet in result:\n",
    "        posts_dict['date'].append(tweet['created_at'])\n",
    "        posts_dict['text'].append(tweet['text'])\n",
    "        posts_dict['like_count'].append(tweet['public_metrics']['like_count'])\n",
    "        posts_dict['quote_count'].append(tweet['public_metrics']['quote_count'])\n",
    "        posts_dict['reply_count'].append(tweet['public_metrics']['reply_count'])\n",
    "        posts_dict['retweet_count'].append(tweet['public_metrics']['retweet_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "159622c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dictionary of posts to dataframe\n",
    "twitter_df = pd.DataFrame.from_dict(posts_dict)\n",
    "twitter_df.head()\n",
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c62e0",
   "metadata": {},
   "source": [
    "## (1.2) Clean the twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "971be6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-14T23:35:39.000Z</td>\n",
       "      <td>Review of Model S Plaid by Dan Neil\\nhttps://t...</td>\n",
       "      <td>29872</td>\n",
       "      <td>189</td>\n",
       "      <td>5195</td>\n",
       "      <td>2617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-14T21:30:25.000Z</td>\n",
       "      <td>Some light reading with lil X https://t.co/MHj...</td>\n",
       "      <td>105566</td>\n",
       "      <td>405</td>\n",
       "      <td>5502</td>\n",
       "      <td>4433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-14T02:42:29.000Z</td>\n",
       "      <td>RT @Tesla: You can stream Netflix &amp;amp; YouTub...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-13T03:05:20.000Z</td>\n",
       "      <td>those who attack space\\nmaybe don’t realize th...</td>\n",
       "      <td>247850</td>\n",
       "      <td>13307</td>\n",
       "      <td>31170</td>\n",
       "      <td>22968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-13T02:37:57.000Z</td>\n",
       "      <td>Loki is pretty good. Basically, live-action @R...</td>\n",
       "      <td>135134</td>\n",
       "      <td>2863</td>\n",
       "      <td>7204</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>2020-06-21T07:03:08.000Z</td>\n",
       "      <td>Mars is my souldog</td>\n",
       "      <td>187069</td>\n",
       "      <td>911</td>\n",
       "      <td>4137</td>\n",
       "      <td>10615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>2020-06-21T06:19:41.000Z</td>\n",
       "      <td>If heat death is the end of the universe, it r...</td>\n",
       "      <td>144392</td>\n",
       "      <td>896</td>\n",
       "      <td>3530</td>\n",
       "      <td>12618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>2020-06-21T05:18:44.000Z</td>\n",
       "      <td>RT @cleantechnica: Exclusive Pro Photos: Tesla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>2020-06-21T00:31:25.000Z</td>\n",
       "      <td>RT @Tesla: https://t.co/26o1bAP14v</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>2020-06-19T17:06:03.000Z</td>\n",
       "      <td>Juneteenth is henceforth considered a US holid...</td>\n",
       "      <td>402524</td>\n",
       "      <td>2590</td>\n",
       "      <td>5885</td>\n",
       "      <td>31264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>849 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         date  \\\n",
       "0    2021-07-14T23:35:39.000Z   \n",
       "1    2021-07-14T21:30:25.000Z   \n",
       "2    2021-07-14T02:42:29.000Z   \n",
       "3    2021-07-13T03:05:20.000Z   \n",
       "4    2021-07-13T02:37:57.000Z   \n",
       "..                        ...   \n",
       "844  2020-06-21T07:03:08.000Z   \n",
       "845  2020-06-21T06:19:41.000Z   \n",
       "846  2020-06-21T05:18:44.000Z   \n",
       "847  2020-06-21T00:31:25.000Z   \n",
       "848  2020-06-19T17:06:03.000Z   \n",
       "\n",
       "                                                  text  like_count  \\\n",
       "0    Review of Model S Plaid by Dan Neil\\nhttps://t...       29872   \n",
       "1    Some light reading with lil X https://t.co/MHj...      105566   \n",
       "2    RT @Tesla: You can stream Netflix &amp; YouTub...           0   \n",
       "3    those who attack space\\nmaybe don’t realize th...      247850   \n",
       "4    Loki is pretty good. Basically, live-action @R...      135134   \n",
       "..                                                 ...         ...   \n",
       "844                                 Mars is my souldog      187069   \n",
       "845  If heat death is the end of the universe, it r...      144392   \n",
       "846  RT @cleantechnica: Exclusive Pro Photos: Tesla...           0   \n",
       "847                 RT @Tesla: https://t.co/26o1bAP14v           0   \n",
       "848  Juneteenth is henceforth considered a US holid...      402524   \n",
       "\n",
       "     quote_count  reply_count  retweet_count  \n",
       "0            189         5195           2617  \n",
       "1            405         5502           4433  \n",
       "2              0            0           2793  \n",
       "3          13307        31170          22968  \n",
       "4           2863         7204           9106  \n",
       "..           ...          ...            ...  \n",
       "844          911         4137          10615  \n",
       "845          896         3530          12618  \n",
       "846            0            0            529  \n",
       "847            0            0           2167  \n",
       "848         2590         5885          31264  \n",
       "\n",
       "[849 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the NaNs\n",
    "twitter_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "863da221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             object\n",
       "text             object\n",
       "like_count        int64\n",
       "quote_count       int64\n",
       "reply_count       int64\n",
       "retweet_count     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine data types for each column\n",
    "twitter_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aba95493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "378beb62",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>Review of Model S Plaid by Dan Neil\\nhttps://t...</td>\n",
       "      <td>29872</td>\n",
       "      <td>189</td>\n",
       "      <td>5195</td>\n",
       "      <td>2617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>Some light reading with lil X https://t.co/MHj...</td>\n",
       "      <td>105566</td>\n",
       "      <td>405</td>\n",
       "      <td>5502</td>\n",
       "      <td>4433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>RT @Tesla: You can stream Netflix &amp;amp; YouTub...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>those who attack space\\nmaybe don’t realize th...</td>\n",
       "      <td>247850</td>\n",
       "      <td>13307</td>\n",
       "      <td>31170</td>\n",
       "      <td>22968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>Loki is pretty good. Basically, live-action @R...</td>\n",
       "      <td>135134</td>\n",
       "      <td>2863</td>\n",
       "      <td>7204</td>\n",
       "      <td>9106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                               text  like_count  \\\n",
       "0 2021-07-14  Review of Model S Plaid by Dan Neil\\nhttps://t...       29872   \n",
       "1 2021-07-14  Some light reading with lil X https://t.co/MHj...      105566   \n",
       "2 2021-07-14  RT @Tesla: You can stream Netflix &amp; YouTub...           0   \n",
       "3 2021-07-13  those who attack space\\nmaybe don’t realize th...      247850   \n",
       "4 2021-07-13  Loki is pretty good. Basically, live-action @R...      135134   \n",
       "\n",
       "   quote_count  reply_count  retweet_count  \n",
       "0          189         5195           2617  \n",
       "1          405         5502           4433  \n",
       "2            0            0           2793  \n",
       "3        13307        31170          22968  \n",
       "4         2863         7204           9106  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's convert the date.\n",
    "twitter_df['date'] = pd.to_datetime(twitter_df['date']).dt.date.astype('datetime64')\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b731df31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "\n",
    "def f(x):\n",
    "     return Series(dict(like_count = x['like_count'].sum(),\n",
    "                        quote_count = x['quote_count'].sum(),\n",
    "                        reply_count = x['reply_count'].sum(),\n",
    "                        retweet_count = x['retweet_count'].sum(),\n",
    "                        text = \"{%s}\" % ', '.join(x['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d661c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>402524</td>\n",
       "      <td>2590</td>\n",
       "      <td>5885</td>\n",
       "      <td>31264</td>\n",
       "      <td>{Juneteenth is henceforth considered a US holi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>735049</td>\n",
       "      <td>4879</td>\n",
       "      <td>17986</td>\n",
       "      <td>57388</td>\n",
       "      <td>{2019 seems so quaint &amp;amp; long ago https://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>133410</td>\n",
       "      <td>892</td>\n",
       "      <td>5246</td>\n",
       "      <td>5438</td>\n",
       "      <td>{Tentative date for Tesla Shareholder Meeting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>259070</td>\n",
       "      <td>1039</td>\n",
       "      <td>4758</td>\n",
       "      <td>10803</td>\n",
       "      <td>{RT @GerberKawasaki: First thoughts driving my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>2246092</td>\n",
       "      <td>24437</td>\n",
       "      <td>32927</td>\n",
       "      <td>300068</td>\n",
       "      <td>{.@JeffBezos is a copy 🐈 haha https://t.co/plR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  like_count  quote_count  reply_count  retweet_count  \\\n",
       "0 2020-06-19      402524         2590         5885          31264   \n",
       "1 2020-06-21      735049         4879        17986          57388   \n",
       "2 2020-06-22      133410          892         5246           5438   \n",
       "3 2020-06-25      259070         1039         4758          10803   \n",
       "4 2020-06-26     2246092        24437        32927         300068   \n",
       "\n",
       "                                                text  \n",
       "0  {Juneteenth is henceforth considered a US holi...  \n",
       "1  {2019 seems so quaint &amp; long ago https://t...  \n",
       "2  {Tentative date for Tesla Shareholder Meeting ...  \n",
       "3  {RT @GerberKawasaki: First thoughts driving my...  \n",
       "4  {.@JeffBezos is a copy 🐈 haha https://t.co/plR...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = twitter_df.groupby('date').apply(f).reset_index()\n",
    "twitter_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad7518",
   "metadata": {},
   "source": [
    "## (1.3) Preprocessing the Twitter data\n",
    "\n",
    "**Preprocess the data by making it all lowercase. Remove a reasonable set of stopwords from the dataset and tokenize. Then, report the 10 most common words and their count. We need to iterate this process, adding some stop words as we understand the structure of the data. Justify additional stop words we've added.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1c50479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weren', 'didn', 't', 'about', \"hasn't\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Pre-processing and make the tweets all lowercase and remove stopwords.\n",
    "from nltk.corpus import stopwords\n",
    "en_stop_words = set(stopwords.words('english'))\n",
    "list(en_stop_words)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0fd768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weren', 'didn', 't', 'about', \"hasn't\", 'be', 'wasn', 'since', 'or', 'btw', 'whom', \"aren't\", 'down', 'during', 'they', 'is', 'kms', 'est', 'her', 'just', 'doesn', 'bs', 'was', \"that'll\", 'vs', \"you're\", 'yourselves', 'ii', \"should've\", 'an', 'actually', 'hasn', 'not', 'so', 'herself', 'also', 'only', 'yesterday', 'won', 'you', 'hadn', 'there', 'most', 'mustn', 'don', 'shan', 'here’s', 'et', 'off', 'ain', 'all', \"mustn't\", 'above', 're', \"wasn't\", 'such', 'ourselves', 'nd', 'than', 'who', 'us', 'its', \"it's\", 'via', 'own', 'now', \"isn't\", 'some', 'ur', \"won't\", 'where', 'what', 'after', 'can', 'gt', 'here', 'over', 've', 'has', 'ours', 'it', 'these', 'through', 'this', 'my', \"couldn't\", 'your', 'daca', 'those', 'very', 'under', \"you'd\", 'am', 'to', \"you've\", \"haven't\", 'will', 'himself', 'does', 'myself', \"wouldn't\", 'rt', '&amp;', 'needn', 'yours', 'when', 'before', 'further', 'itself', 'were', \"weren't\", \"shan't\", 'that', 'com', 'and', 'against', 'inu', 'same', 'until', 'th', 'me', 'mightn', 'theirs', 'with', 'out', 'd', 'been', 'kim', 'em', 'hers', 'for', 'she', 'at', 'ft', 'iii', \"she's\", 'few', 'y', 'lz', 'more', 'each', 'did', 'but', 'couldn', 'yourself', 'too', 'as', \"needn't\", \"mightn't\", 'up', 'have', 'doing', 'into', 'https', 'him', 'm', 'la', 'i', 'rd', 'between', 'below', 'pcr', \"don't\", 'due', 'which', 'in', 'co', 's', 'nor', 'of', 'how', \"shouldn't\", 'any', 'our', 'their', 'o', 'had', 'haha', 'the', \"didn't\", 'from', 'are', 'shouldn', 'aft', 'no', 'wow', 'do', 'by', 'haven', 'his', 'he', 'aren', 'themselves', 'why', 'then', 'on', 'again', 'ma', \"hadn't\", 'http', \"doesn't\", 'having', 'should', 'isn', 'them', 'wouldn', 'st', 'both', 'because', 'other', 'km', 'we', 'being', \"you'll\", 'while', 'once', 'll', 'a', 'if'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zkirsan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>402524</td>\n",
       "      <td>2590</td>\n",
       "      <td>5885</td>\n",
       "      <td>31264</td>\n",
       "      <td>{Juneteenth is henceforth considered a US holi...</td>\n",
       "      <td>juneteenth henceforth considered holiday tesla...</td>\n",
       "      <td>[juneteenth, henceforth, considered, holiday, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>735049</td>\n",
       "      <td>4879</td>\n",
       "      <td>17986</td>\n",
       "      <td>57388</td>\n",
       "      <td>{2019 seems so quaint &amp;amp; long ago https://t...</td>\n",
       "      <td>2019 seems quaint long ago purpose, tesla biow...</td>\n",
       "      <td>[seems, quaint, long, ago, purpose, tesla, bio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>133410</td>\n",
       "      <td>892</td>\n",
       "      <td>5246</td>\n",
       "      <td>5438</td>\n",
       "      <td>{Tentative date for Tesla Shareholder Meeting ...</td>\n",
       "      <td>tentative date tesla shareholder meeting batte...</td>\n",
       "      <td>[tentative, date, tesla, shareholder, meeting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>259070</td>\n",
       "      <td>1039</td>\n",
       "      <td>4758</td>\n",
       "      <td>10803</td>\n",
       "      <td>{RT @GerberKawasaki: First thoughts driving my...</td>\n",
       "      <td>@gerberkawasaki: first thoughts driving new te...</td>\n",
       "      <td>[gerberkawasaki, first, thoughts, driving, new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>2246092</td>\n",
       "      <td>24437</td>\n",
       "      <td>32927</td>\n",
       "      <td>300068</td>\n",
       "      <td>{.@JeffBezos is a copy 🐈 haha https://t.co/plR...</td>\n",
       "      <td>.@jeffbezos copy 🐈 controls memes, controls un...</td>\n",
       "      <td>[jeffbezos, copy, controls, memes, controls, u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  like_count  quote_count  reply_count  retweet_count  \\\n",
       "0 2020-06-19      402524         2590         5885          31264   \n",
       "1 2020-06-21      735049         4879        17986          57388   \n",
       "2 2020-06-22      133410          892         5246           5438   \n",
       "3 2020-06-25      259070         1039         4758          10803   \n",
       "4 2020-06-26     2246092        24437        32927         300068   \n",
       "\n",
       "                                                text  \\\n",
       "0  {Juneteenth is henceforth considered a US holi...   \n",
       "1  {2019 seems so quaint &amp; long ago https://t...   \n",
       "2  {Tentative date for Tesla Shareholder Meeting ...   \n",
       "3  {RT @GerberKawasaki: First thoughts driving my...   \n",
       "4  {.@JeffBezos is a copy 🐈 haha https://t.co/plR...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  juneteenth henceforth considered holiday tesla...   \n",
       "1  2019 seems quaint long ago purpose, tesla biow...   \n",
       "2  tentative date tesla shareholder meeting batte...   \n",
       "3  @gerberkawasaki: first thoughts driving new te...   \n",
       "4  .@jeffbezos copy 🐈 controls memes, controls un...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [juneteenth, henceforth, considered, holiday, ...  \n",
       "1  [seems, quaint, long, ago, purpose, tesla, bio...  \n",
       "2  [tentative, date, tesla, shareholder, meeting,...  \n",
       "3  [gerberkawasaki, first, thoughts, driving, new...  \n",
       "4  [jeffbezos, copy, controls, memes, controls, u...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from datetime import datetime\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "\n",
    "date_col='date'\n",
    "tweet_col='text'\n",
    "like_count= 'like_count'\n",
    "quote_count= 'quote_count'\n",
    "reply_count= 'reply_count'\n",
    "retweet_count= 'retweet_count'\n",
    "\n",
    "# lower the tweets\n",
    "twitter_df['preprocessed_' + tweet_col] = twitter_df[tweet_col].str.lower()\n",
    "\n",
    "# remove apostrophe from words and curly braces\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"^{\", \"\", row) for row in twitter_df['preprocessed_text']]\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"}\\Z\", \"\", row) for row in twitter_df['preprocessed_text']]\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"('[a-z])\\s\", \"\", row) for row in twitter_df['preprocessed_text']]\n",
    "\n",
    "                                      \n",
    "# filter out stop words and URLs\n",
    "en_stop_words = set(stopwords.words('english'))\n",
    "extended_stop_words = en_stop_words | \\\n",
    "                    {\n",
    "                        '&amp;', 'rt',                            \n",
    "                          'th','co', 're', 've', 'kim', 'daca', 'us', 'it', 'th', 'you', 'haha', 'st', 'et', 'so', 'iii',\n",
    "                        'also', 've', 'la', 're', 'the', 'https', 'wow', 'actually', 'due', 'ft', 'pcr', 'via', 'am', 'gt',\n",
    "                        'com', 'since', 'in', 'me', 'and', 'btw', 'yesterday', 'ii', 'inu', 'on', 'http', 'to', 'vs', 'rd', \n",
    "                        'ur', 'of', 'bs', 'km', 'est', 'em', 'lz', 'kms', 'aft', 'nd',  'here’s'\n",
    "                    }\n",
    "print(extended_stop_words)\n",
    "\n",
    "url_re = '(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})'        \n",
    "\n",
    "twitter_df['preprocessed_' + tweet_col] = twitter_df['preprocessed_' + tweet_col].apply(lambda row: ' '.join([word for word in row.split() if (not word in extended_stop_words) and (not re.match(url_re, word))]))\n",
    "\n",
    "# tokenize the tweets\n",
    "tokenizer = RegexpTokenizer('[a-zA-Z]\\w+\\'?\\w*')\n",
    "\n",
    "\n",
    "#create an object of class PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# apply stemming\n",
    "twitter_df['preprocessed_text'] = [porter.stem(row) for row in twitter_df['preprocessed_text']]   \n",
    "\n",
    "twitter_df['tokenized_' + tweet_col] = twitter_df['preprocessed_' + tweet_col].apply(lambda row: tokenizer.tokenize(row))\n",
    "\n",
    "df_tweets_clean = twitter_df\n",
    "df_tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caba4f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>{Juneteenth is henceforth considered a US holi...</td>\n",
       "      <td>juneteenth henceforth considered holiday tesla...</td>\n",
       "      <td>[juneteenth, henceforth, considered, holiday, ...</td>\n",
       "      <td>402524</td>\n",
       "      <td>2590</td>\n",
       "      <td>5885</td>\n",
       "      <td>31264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>{2019 seems so quaint &amp;amp; long ago https://t...</td>\n",
       "      <td>2019 seems quaint long ago purpose, tesla biow...</td>\n",
       "      <td>[seems, quaint, long, ago, purpose, tesla, bio...</td>\n",
       "      <td>735049</td>\n",
       "      <td>4879</td>\n",
       "      <td>17986</td>\n",
       "      <td>57388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>{Tentative date for Tesla Shareholder Meeting ...</td>\n",
       "      <td>tentative date tesla shareholder meeting batte...</td>\n",
       "      <td>[tentative, date, tesla, shareholder, meeting,...</td>\n",
       "      <td>133410</td>\n",
       "      <td>892</td>\n",
       "      <td>5246</td>\n",
       "      <td>5438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>{RT @GerberKawasaki: First thoughts driving my...</td>\n",
       "      <td>@gerberkawasaki: first thoughts driving new te...</td>\n",
       "      <td>[gerberkawasaki, first, thoughts, driving, new...</td>\n",
       "      <td>259070</td>\n",
       "      <td>1039</td>\n",
       "      <td>4758</td>\n",
       "      <td>10803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>{.@JeffBezos is a copy 🐈 haha https://t.co/plR...</td>\n",
       "      <td>.@jeffbezos copy 🐈 controls memes, controls un...</td>\n",
       "      <td>[jeffbezos, copy, controls, memes, controls, u...</td>\n",
       "      <td>2246092</td>\n",
       "      <td>24437</td>\n",
       "      <td>32927</td>\n",
       "      <td>300068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>{Btw, Tesla actually receives *least* subsidie...</td>\n",
       "      <td>btw, tesla receives *least* subsidies automake...</td>\n",
       "      <td>[btw, tesla, receives, least, subsidies, autom...</td>\n",
       "      <td>549375</td>\n",
       "      <td>5325</td>\n",
       "      <td>10657</td>\n",
       "      <td>55441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>{Your GPS just got slightly better https://t.c...</td>\n",
       "      <td>gps got slightly better @spacex: falcon 9’s fi...</td>\n",
       "      <td>[gps, got, slightly, better, spacex, falcon, f...</td>\n",
       "      <td>156672</td>\n",
       "      <td>688</td>\n",
       "      <td>2610</td>\n",
       "      <td>21575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>{Tesla Impact Report (repost). We do everythin...</td>\n",
       "      <td>tesla impact report (repost). everything human...</td>\n",
       "      <td>[tesla, impact, report, repost, everything, hu...</td>\n",
       "      <td>26857</td>\n",
       "      <td>208</td>\n",
       "      <td>1657</td>\n",
       "      <td>2530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>{Thanks Tesla owners &amp;amp; investors! Love you...</td>\n",
       "      <td>thanks tesla owners investors! love you!! work...</td>\n",
       "      <td>[thanks, tesla, owners, investors, love, you, ...</td>\n",
       "      <td>600485</td>\n",
       "      <td>11573</td>\n",
       "      <td>31284</td>\n",
       "      <td>39497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-07-04</td>\n",
       "      <td>{Please take a moment to report accounts clear...</td>\n",
       "      <td>please take moment report accounts clearly eng...</td>\n",
       "      <td>[please, take, moment, report, accounts, clear...</td>\n",
       "      <td>377757</td>\n",
       "      <td>2674</td>\n",
       "      <td>15608</td>\n",
       "      <td>32526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                               text  \\\n",
       "0 2020-06-19  {Juneteenth is henceforth considered a US holi...   \n",
       "1 2020-06-21  {2019 seems so quaint &amp; long ago https://t...   \n",
       "2 2020-06-22  {Tentative date for Tesla Shareholder Meeting ...   \n",
       "3 2020-06-25  {RT @GerberKawasaki: First thoughts driving my...   \n",
       "4 2020-06-26  {.@JeffBezos is a copy 🐈 haha https://t.co/plR...   \n",
       "5 2020-06-28  {Btw, Tesla actually receives *least* subsidie...   \n",
       "6 2020-06-30  {Your GPS just got slightly better https://t.c...   \n",
       "7 2020-07-01  {Tesla Impact Report (repost). We do everythin...   \n",
       "8 2020-07-02  {Thanks Tesla owners &amp; investors! Love you...   \n",
       "9 2020-07-04  {Please take a moment to report accounts clear...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  juneteenth henceforth considered holiday tesla...   \n",
       "1  2019 seems quaint long ago purpose, tesla biow...   \n",
       "2  tentative date tesla shareholder meeting batte...   \n",
       "3  @gerberkawasaki: first thoughts driving new te...   \n",
       "4  .@jeffbezos copy 🐈 controls memes, controls un...   \n",
       "5  btw, tesla receives *least* subsidies automake...   \n",
       "6  gps got slightly better @spacex: falcon 9’s fi...   \n",
       "7  tesla impact report (repost). everything human...   \n",
       "8  thanks tesla owners investors! love you!! work...   \n",
       "9  please take moment report accounts clearly eng...   \n",
       "\n",
       "                                      tokenized_text  like_count  quote_count  \\\n",
       "0  [juneteenth, henceforth, considered, holiday, ...      402524         2590   \n",
       "1  [seems, quaint, long, ago, purpose, tesla, bio...      735049         4879   \n",
       "2  [tentative, date, tesla, shareholder, meeting,...      133410          892   \n",
       "3  [gerberkawasaki, first, thoughts, driving, new...      259070         1039   \n",
       "4  [jeffbezos, copy, controls, memes, controls, u...     2246092        24437   \n",
       "5  [btw, tesla, receives, least, subsidies, autom...      549375         5325   \n",
       "6  [gps, got, slightly, better, spacex, falcon, f...      156672          688   \n",
       "7  [tesla, impact, report, repost, everything, hu...       26857          208   \n",
       "8  [thanks, tesla, owners, investors, love, you, ...      600485        11573   \n",
       "9  [please, take, moment, report, accounts, clear...      377757         2674   \n",
       "\n",
       "   reply_count  retweet_count  \n",
       "0         5885          31264  \n",
       "1        17986          57388  \n",
       "2         5246           5438  \n",
       "3         4758          10803  \n",
       "4        32927         300068  \n",
       "5        10657          55441  \n",
       "6         2610          21575  \n",
       "7         1657           2530  \n",
       "8        31284          39497  \n",
       "9        15608          32526  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_clean = df_tweets_clean[['date', 'text', 'preprocessed_text', 'tokenized_text', 'like_count', 'quote_count', 'reply_count', 'retweet_count']]\n",
    "df_tweets_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6338deb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spacex', 170),\n",
       " ('tesla', 114),\n",
       " ('launch', 56),\n",
       " ('dragon', 55),\n",
       " ('falcon', 53),\n",
       " ('first', 44),\n",
       " ('nasa', 36),\n",
       " ('crew', 35),\n",
       " ('model', 29),\n",
       " ('mission', 27)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the most common words and their count\n",
    "def get_most_freq_words(str, n=None):\n",
    "    vect = CountVectorizer().fit(str)\n",
    "    bag_of_words = vect.transform(str)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
    "    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n",
    "    return freq[:n]\n",
    "  \n",
    "get_most_freq_words([ word for tweet in df_tweets_clean.tokenized_text for word in tweet],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "effaa3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.to_csv('data/tweets_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf788124",
   "metadata": {},
   "source": [
    "# (2 ) Stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c8153",
   "metadata": {},
   "source": [
    "## (2.1) Getting the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5ee54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from yahoo_fin.stock_info import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "725dce38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.508000</td>\n",
       "      <td>4.778000</td>\n",
       "      <td>4.778000</td>\n",
       "      <td>93831500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>5.158000</td>\n",
       "      <td>6.084000</td>\n",
       "      <td>4.660000</td>\n",
       "      <td>4.766000</td>\n",
       "      <td>4.766000</td>\n",
       "      <td>85935500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.184000</td>\n",
       "      <td>4.054000</td>\n",
       "      <td>4.392000</td>\n",
       "      <td>4.392000</td>\n",
       "      <td>41094000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>3.742000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>25699000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.166000</td>\n",
       "      <td>3.222000</td>\n",
       "      <td>3.222000</td>\n",
       "      <td>34334500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>628.369995</td>\n",
       "      <td>654.429993</td>\n",
       "      <td>620.460022</td>\n",
       "      <td>652.809998</td>\n",
       "      <td>652.809998</td>\n",
       "      <td>22773300</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>2021-07-09</td>\n",
       "      <td>653.179993</td>\n",
       "      <td>658.909973</td>\n",
       "      <td>644.690002</td>\n",
       "      <td>656.950012</td>\n",
       "      <td>656.950012</td>\n",
       "      <td>18118500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777</th>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>662.200012</td>\n",
       "      <td>687.239990</td>\n",
       "      <td>662.159973</td>\n",
       "      <td>685.700012</td>\n",
       "      <td>685.700012</td>\n",
       "      <td>25927000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2778</th>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>686.320007</td>\n",
       "      <td>693.280029</td>\n",
       "      <td>666.299988</td>\n",
       "      <td>668.539978</td>\n",
       "      <td>668.539978</td>\n",
       "      <td>20847500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2779</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>670.750000</td>\n",
       "      <td>678.609985</td>\n",
       "      <td>652.840027</td>\n",
       "      <td>653.380005</td>\n",
       "      <td>653.380005</td>\n",
       "      <td>21612700</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2780 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date        open        high         low       close    adjclose  \\\n",
       "0    2010-06-29    3.800000    5.000000    3.508000    4.778000    4.778000   \n",
       "1    2010-06-30    5.158000    6.084000    4.660000    4.766000    4.766000   \n",
       "2    2010-07-01    5.000000    5.184000    4.054000    4.392000    4.392000   \n",
       "3    2010-07-02    4.600000    4.620000    3.742000    3.840000    3.840000   \n",
       "4    2010-07-06    4.000000    4.000000    3.166000    3.222000    3.222000   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "2775 2021-07-08  628.369995  654.429993  620.460022  652.809998  652.809998   \n",
       "2776 2021-07-09  653.179993  658.909973  644.690002  656.950012  656.950012   \n",
       "2777 2021-07-12  662.200012  687.239990  662.159973  685.700012  685.700012   \n",
       "2778 2021-07-13  686.320007  693.280029  666.299988  668.539978  668.539978   \n",
       "2779 2021-07-14  670.750000  678.609985  652.840027  653.380005  653.380005   \n",
       "\n",
       "        volume ticker  \n",
       "0     93831500   TSLA  \n",
       "1     85935500   TSLA  \n",
       "2     41094000   TSLA  \n",
       "3     25699000   TSLA  \n",
       "4     34334500   TSLA  \n",
       "...        ...    ...  \n",
       "2775  22773300   TSLA  \n",
       "2776  18118500   TSLA  \n",
       "2777  25927000   TSLA  \n",
       "2778  20847500   TSLA  \n",
       "2779  21612700   TSLA  \n",
       "\n",
       "[2780 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# historical daily data from Yahoo finance\n",
    "tesla_df = get_data(\"tsla\", start_date = None, end_date = None, index_as_date = False, interval=\"1d\")\n",
    "tesla_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e57be6",
   "metadata": {},
   "source": [
    "## (2.2) Clean the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72eba53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>3.800</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.508</td>\n",
       "      <td>4.778</td>\n",
       "      <td>93831500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>5.158</td>\n",
       "      <td>6.084</td>\n",
       "      <td>4.660</td>\n",
       "      <td>4.766</td>\n",
       "      <td>85935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.184</td>\n",
       "      <td>4.054</td>\n",
       "      <td>4.392</td>\n",
       "      <td>41094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>4.600</td>\n",
       "      <td>4.620</td>\n",
       "      <td>3.742</td>\n",
       "      <td>3.840</td>\n",
       "      <td>25699000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.166</td>\n",
       "      <td>3.222</td>\n",
       "      <td>34334500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close    volume\n",
       "0 2010-06-29  3.800  5.000  3.508  4.778  93831500\n",
       "1 2010-06-30  5.158  6.084  4.660  4.766  85935500\n",
       "2 2010-07-01  5.000  5.184  4.054  4.392  41094000\n",
       "3 2010-07-02  4.600  4.620  3.742  3.840  25699000\n",
       "4 2010-07-06  4.000  4.000  3.166  3.222  34334500"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop adjclose column\n",
    "tesla_df = tesla_df.drop(columns=[\"adjclose\", \"ticker\"])\n",
    "tesla_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fff742f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date      datetime64[ns]\n",
       "open             float64\n",
       "high             float64\n",
       "low              float64\n",
       "close            float64\n",
       "volume             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine data types for each column\n",
    "tesla_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc19c0",
   "metadata": {},
   "source": [
    "## (2.3) Preprocessing the Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f772a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-29</td>\n",
       "      <td>3.800</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.508</td>\n",
       "      <td>4.778</td>\n",
       "      <td>93831500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>5.158</td>\n",
       "      <td>6.084</td>\n",
       "      <td>4.660</td>\n",
       "      <td>4.766</td>\n",
       "      <td>85935500</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-01</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.184</td>\n",
       "      <td>4.054</td>\n",
       "      <td>4.392</td>\n",
       "      <td>41094000</td>\n",
       "      <td>-0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>4.600</td>\n",
       "      <td>4.620</td>\n",
       "      <td>3.742</td>\n",
       "      <td>3.840</td>\n",
       "      <td>25699000</td>\n",
       "      <td>-0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-06</td>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.166</td>\n",
       "      <td>3.222</td>\n",
       "      <td>34334500</td>\n",
       "      <td>-0.618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-07-07</td>\n",
       "      <td>3.280</td>\n",
       "      <td>3.326</td>\n",
       "      <td>2.996</td>\n",
       "      <td>3.160</td>\n",
       "      <td>34608500</td>\n",
       "      <td>-0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-07-08</td>\n",
       "      <td>3.228</td>\n",
       "      <td>3.504</td>\n",
       "      <td>3.114</td>\n",
       "      <td>3.492</td>\n",
       "      <td>38557000</td>\n",
       "      <td>0.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-07-09</td>\n",
       "      <td>3.516</td>\n",
       "      <td>3.580</td>\n",
       "      <td>3.310</td>\n",
       "      <td>3.480</td>\n",
       "      <td>20253000</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-07-12</td>\n",
       "      <td>3.590</td>\n",
       "      <td>3.614</td>\n",
       "      <td>3.400</td>\n",
       "      <td>3.410</td>\n",
       "      <td>11012500</td>\n",
       "      <td>-0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-07-13</td>\n",
       "      <td>3.478</td>\n",
       "      <td>3.728</td>\n",
       "      <td>3.380</td>\n",
       "      <td>3.628</td>\n",
       "      <td>13400500</td>\n",
       "      <td>0.218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close    volume  change\n",
       "0 2010-06-29  3.800  5.000  3.508  4.778  93831500     NaN\n",
       "1 2010-06-30  5.158  6.084  4.660  4.766  85935500  -0.012\n",
       "2 2010-07-01  5.000  5.184  4.054  4.392  41094000  -0.374\n",
       "3 2010-07-02  4.600  4.620  3.742  3.840  25699000  -0.552\n",
       "4 2010-07-06  4.000  4.000  3.166  3.222  34334500  -0.618\n",
       "5 2010-07-07  3.280  3.326  2.996  3.160  34608500  -0.062\n",
       "6 2010-07-08  3.228  3.504  3.114  3.492  38557000   0.332\n",
       "7 2010-07-09  3.516  3.580  3.310  3.480  20253000  -0.012\n",
       "8 2010-07-12  3.590  3.614  3.400  3.410  11012500  -0.070\n",
       "9 2010-07-13  3.478  3.728  3.380  3.628  13400500   0.218"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate change in stock price\n",
    "tesla_df['change'] = tesla_df['close'].diff()\n",
    "tesla_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d712d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.to_csv('data/tesla_stocks', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dcd05f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
